{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# National Oceanic and Atmospheric Administration (NOAA)\n",
    "This jupyter notebook is meant to be used along with the North American Mesoscale Forecast System (NAM) dataset.  \n",
    "This dataset can be found online under \"Data Access > Model > Datasets > NAM\" on the NOAA website.  \n",
    "Once the data has been properly requested, confirmed, and processed using NOAA's Order Data feature,  \n",
    "the requester is given 5 days to download the data via a email-link.  \n",
    "\n",
    "# NAM 2017\n",
    "To be more specific, the range this notebook will be targetting is the entire 2017 year (1800 UTC only). (100 ish Gb)  \n",
    "Through further observation of the email-link provided by NOAA, it can be seen that the files end in an extension \".tar\".  \n",
    "These are all just zipped files. BEWARE- unpacking all these files doubles the 100Gb to 200Gb.  \n",
    "It is recommended to make a main folder (moddata) with subfolders with each month on them (01, 02, 03, ..., 12).  \n",
    "Then, putting all the corresponding \".tar\" files in their respective month folder. The idea is to unpack an entire month and then delete the \".tar\" files for that month. That way you don't have to unpack 100Gb to 200Gb and then try to delete 100Gb. It will be more like unpacking 6Gb to 12Gb then deleting the .tar files to regain space.\n",
    "\n",
    "# Unpacking \".tar\" Files\n",
    "The \".tar\" file names should look like the following:\n",
    "\n",
    "namanl_218_2017010118.g2.tar\n",
    "\n",
    "The format is very simple: namanl_218_yyyymmddhh.g2.tar  \n",
    "Where yyyy = year, mm = month, dd = day, hh = hour (UTC)  \n",
    "The above file would then be of 2017 January 1st 18 UTC\n",
    "\n",
    "Since this data ranges accross the entire North America continent, 18 UTC was chosen. In New York, 18 UTC translates to 2 P.M. This makes any \"real images\" from the dataset appear more visually appealing since that part of the Earth will be facing towards the sun. This would be better than \"real images\" of NA taken at night. This also saves a lot of space. Imagine simply having 2 timestamps per day instead of 1, this would easily double the size of the data. NOAA allows 4 timestamps per day (0 UTC, 6 UTC, 12 UTC, and 18 UTC).  \n",
    "\n",
    "Once you're inside the month directory containing all the \".tar\" files for that month, simply use the following command to unpack:\n",
    "\n",
    "// assuming path /moddata/01 being the path to all of january's \".tar\" files type  \n",
    "// and that you are currently inside the /01 directory, type the following into the kernel:  \n",
    "for f in *.tar; do tar -xvf $f; done\n",
    "\n",
    "This command should run for about 20 seconds and you should see all the files being unpacked individually.  \n",
    "For every \".tar\" file unpacked, there should be 5 \".grb2\" files\n",
    "\n",
    "// now type the following command to delete all of the \".tar\" files in that directory:  \n",
    "rm -r *.tar\n",
    "\n",
    "This is done for all 12 months until every subdirectory of /moddata contains only \".grb2\" files.  \n",
    "The new file format should be:\n",
    "\n",
    "nam_218_20170101_1800_000.grb2\n",
    "\n",
    "nam_218_yyyymmdd_hhhh_band.grb2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "Once all of the \".grb2\" for every month are neatly organized in their own folder, the Exploritory Data Analysis can begin!  \n",
    "These files can be viewed using a python package called \"pygrib\".\n",
    "\n",
    "If you have anaconda installed, simply use:  \n",
    "conda install -c conda-forge pygrib\n",
    "\n",
    "That's about it for installations. Now let's dive into the code--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygrib # used to view \".grb2\" files\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_grbs(grbs):\n",
    "    \"\"\"\n",
    "    grbs: grbs = pygrib.open(\"filepath.grb2\"), grbs is a pygrib object\n",
    "    this function displays all the meta-data for the current pygrib file opened\n",
    "    \"\"\"\n",
    "    for grb in grbs:\n",
    "        print(grb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths(filepath, year = 0, month = 0, band = 0, everything = 0,):\n",
    "    \"\"\"\n",
    "    filepath: a string containing the file path to the directory containing all the .grb2 files\n",
    "    \"\"\"\n",
    "    if (everything != 0):\n",
    "        years = [2017]\n",
    "        months = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "        month_days = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "        bands = [0, 1, 2, 3, 6]\n",
    "        lst = []\n",
    "        for month in months:\n",
    "            for day in range(1, month_days[month - 1] + 1):\n",
    "                for year in years:\n",
    "                    for band in bands:\n",
    "                        if (month < 10 and day < 10):\n",
    "                            lst.append(filepath + \"/nam_218_\" + str(year) + \"0\" + str(month) + \"0\" + str(day) + \"_1800_00\" + str(band) + \".grb2\")\n",
    "                        elif (month < 10 and day >= 10):\n",
    "                            lst.append(filepath + \"/nam_218_\" + str(year) + \"0\" + str(month) + str(day) + \"_1800_00\" + str(band) + \".grb2\")\n",
    "                        elif (month >= 10 and day < 10):\n",
    "                            lst.append(filepath + \"/nam_218_\" + str(year) + str(month) + \"0\" + str(day) + \"_1800_00\" + str(band) + \".grb2\")\n",
    "                        else:\n",
    "                            lst.append(filepath + \"/nam_218_\" + str(year) + str(month) + str(day) + \"_1800_00\" + str(band) + \".grb2\")\n",
    "        return lst\n",
    "    else:\n",
    "        month_days = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "        lst = []\n",
    "        for day in range(1,month_days[month - 1] + 1):\n",
    "            if (month < 10 and day < 10):\n",
    "                lst.append(filepath + \"/nam_218_\" + str(year) + \"0\" + str(month) + \"0\" + str(day) +\"_1800_00\" + str(band) + \".grb2\")\n",
    "            elif (month < 10 and day >= 10):\n",
    "                lst.append(filepath + \"/nam_218_\" + str(year) + \"0\" + str(month) + str(day) +\"_1800_00\" + str(band) + \".grb2\")\n",
    "            elif (month >= 10 and day < 10):\n",
    "                lst.append(filepath + \"/nam_218_\" + str(year) + str(month) + \"0\" + str(day) +\"_1800_00\" + str(band) + \".grb2\")\n",
    "            else:\n",
    "                lst.append(filepath + \"/nam_218_\" + str(year) + str(month) + str(day) +\"_1800_00\" + str(band) + \".grb2\")\n",
    "        return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"/media/sf_moddata/2017\"\n",
    "paths = get_paths(filepath, everything = 1)\n",
    "print(paths[0]) # 2017 january 31 18 utc band 0\n",
    "print(paths[-1]) # 2017 december 31 18 utc band 6\n",
    "print(len(paths)) # 365 days * 5 bands per day = 1825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = get_paths(filepath, 2017, 12, 0)\n",
    "print(dec[0]) # december 1\n",
    "print(dec[-1]) # december 31\n",
    "print(len(dec)) # 31 days * 1 band per day = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's take a look inside this file\n",
    "# print_grbs(grbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by looking at the data above, the unit for temperature is kelvin (K)\n",
    "# there are multiple ways to extract data from a given \"row\"\n",
    "# .values is a numpy command used to return a numpy array\n",
    "temp_surf = grbs.select(name=\"Temperature\")[0].values # temperature at the surface\n",
    "temp_2m = grbs.select(name=\"2 metre temperature\")[0].values # temperature at 2m\n",
    "temp_5000 = grbs[58].values # index 58 is temperature at 5000m\n",
    "snow_depth = grbs[364].values # index 364 is snow depth\n",
    "soil_temp = grbs.select(name=\"Soil Temperature\")[0].values\n",
    "lightning = grbs.select(name=\"Lightning\")[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's just see what all these array's look like\n",
    "print(temp_surf)\n",
    "#print(temp_2m)\n",
    "#print(temp_5000)\n",
    "#print(snow_depth)\n",
    "#print(soil_temp)\n",
    "#print(lightning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try printing some of this data\n",
    "# this should print out a heatmap in the shape of NA. As the altitude increases the temperature decreases\n",
    "ax = sns.heatmap(temp_surf, cbar='true')\n",
    "ax.invert_yaxis() # heatmap would print it upside down if it wasn't for this\n",
    "print(np.max(temp_surf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(temp_2m, cbar='true')\n",
    "ax.invert_yaxis()\n",
    "print(np.max(temp_2m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(temp_5000, cbar='true')\n",
    "ax.invert_yaxis()\n",
    "print(np.max(temp_5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(snow_depth, cbar='true')\n",
    "ax.invert_yaxis()\n",
    "print(np.max(snow_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(lightning, cbar='true')\n",
    "ax.invert_yaxis()\n",
    "print(np.max(lightning))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
