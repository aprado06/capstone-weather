{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# National Oceanic and Atmospheric Administration (NOAA)\n",
    "This jupyter notebook is meant to be used along with the North American Mesoscale Forecast System (NAM) dataset.  \n",
    "This dataset can be found online under \"Data Access > Model > Datasets > NAM\" on the NOAA website.  \n",
    "Once the data has been properly requested, confirmed, and processed using NOAA's Order Data feature,  \n",
    "the requester is given 5 days to download the data via a email-link.  \n",
    "\n",
    "# NAM 2017\n",
    "To be more specific, the range this notebook will be targetting is the entire 2017 year (1800 UTC only). (100 ish Gb)  \n",
    "Through further observation of the email-link provided by NOAA, it can be seen that the files end in an extension \".tar\".  \n",
    "These are all just zipped files. BEWARE- unpacking all these files doubles the 100Gb to 200Gb.  \n",
    "It is recommended to make a main folder (moddata) with subfolders with each month on them (01, 02, 03, ..., 12).  \n",
    "Then, putting all the corresponding \".tar\" files in their respective month folder. The idea is to unpack an entire month and then delete the \".tar\" files for that month. That way you don't have to unpack 100Gb to 200Gb and then try to delete 100Gb. It will be more like unpacking 6Gb to 12Gb then deleting the .tar files to regain space.\n",
    "\n",
    "# Unpacking \".tar\" Files\n",
    "The \".tar\" file names should look like the following:\n",
    "\n",
    "namanl_218_2017010118.g2.tar\n",
    "\n",
    "The format is very simple: namanl_218_yyyymmddhh.g2.tar  \n",
    "Where yyyy = year, mm = month, dd = day, hh = hour (UTC)  \n",
    "The above file would then be of 2017 January 1st 18 UTC\n",
    "\n",
    "Since this data ranges accross the entire North America continent, 18 UTC was chosen. In New York, 18 UTC translates to 2 P.M. This makes any \"real images\" from the dataset appear more visually appealing since that part of the Earth will be facing towards the sun. This would be better than \"real images\" of NA taken at night. This also saves a lot of space. Imagine simply having 2 timestamps per day instead of 1, this would easily double the size of the data. NOAA allows 4 timestamps per day (0 UTC, 6 UTC, 12 UTC, and 18 UTC).  \n",
    "\n",
    "Once you're inside the month directory containing all the \".tar\" files for that month, simply use the following command to unpack:\n",
    "\n",
    "// assuming path /moddata/01 being the path to all of january's \".tar\" files type  \n",
    "// and that you are currently inside the /01 directory, type the following into the kernel:  \n",
    "for f in *.tar; do tar -xvf $f; done\n",
    "\n",
    "This command should run for about 20 seconds and you should see all the files being unpacked individually.  \n",
    "For every \".tar\" file unpacked, there should be 5 \".grb2\" files\n",
    "\n",
    "// now type the following command to delete all of the \".tar\" files in that directory:  \n",
    "rm -r *.tar\n",
    "\n",
    "This is done for all 12 months until every subdirectory of /moddata contains only \".grb2\" files.  \n",
    "The new file format should be:\n",
    "\n",
    "nam_218_20170101_1800_000.grb2\n",
    "\n",
    "nam_218_yyyymmdd_hhhh_band.grb2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "Once all of the \".grb2\" for every month are neatly organized in their own folder, the Exploritory Data Analysis can begin!  \n",
    "These files can be viewed using a python package called \"pygrib\".\n",
    "\n",
    "If you have anaconda installed, simply use:  \n",
    "conda install -c conda-forge pygrib\n",
    "\n",
    "That's about it for installations. Now let's dive into the code--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygrib # used to view \".grb2\" files\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_grbs(filepath):\n",
    "    \"\"\"\n",
    "    filepath: only 1 file path, not a list\n",
    "    this function displays all the meta-data for the given filepath\n",
    "    \"\"\"\n",
    "    grbs = pygrib.open(filepath)\n",
    "    for grb in grbs:\n",
    "        print(grb)\n",
    "    grbs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths(filepath, year = 0, month = 0, band = 0, everything = 0):\n",
    "    \"\"\"\n",
    "    filepath: a string containing the file path to the directory containing all the .grb2 files\n",
    "    year: specific year\n",
    "    month: specific month\n",
    "    band: specific band\n",
    "    everything: if it is 1, then this function returns the entire list of filepaths available\n",
    "    \"\"\"\n",
    "    if (everything != 0):\n",
    "        years = [2017]\n",
    "        months = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "        month_days = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "        bands = [0, 1, 2, 3, 6]\n",
    "        lst = []\n",
    "        for month in months:\n",
    "            for day in range(1, month_days[month - 1] + 1):\n",
    "                for year in years:\n",
    "                    for band in bands:\n",
    "                        if (month < 10 and day < 10):\n",
    "                            lst.append(filepath + \"/nam_218_\" + str(year) + \"0\" + str(month) + \"0\" + str(day) + \"_1800_00\" + str(band) + \".grb2\")\n",
    "                        elif (month < 10 and day >= 10):\n",
    "                            lst.append(filepath + \"/nam_218_\" + str(year) + \"0\" + str(month) + str(day) + \"_1800_00\" + str(band) + \".grb2\")\n",
    "                        elif (month >= 10 and day < 10):\n",
    "                            lst.append(filepath + \"/nam_218_\" + str(year) + str(month) + \"0\" + str(day) + \"_1800_00\" + str(band) + \".grb2\")\n",
    "                        else:\n",
    "                            lst.append(filepath + \"/nam_218_\" + str(year) + str(month) + str(day) + \"_1800_00\" + str(band) + \".grb2\")\n",
    "        return lst\n",
    "    else:\n",
    "        month_days = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "        lst = []\n",
    "        for day in range(1,month_days[month - 1] + 1):\n",
    "            if (month < 10 and day < 10):\n",
    "                lst.append(filepath + \"/nam_218_\" + str(year) + \"0\" + str(month) + \"0\" + str(day) +\"_1800_00\" + str(band) + \".grb2\")\n",
    "            elif (month < 10 and day >= 10):\n",
    "                lst.append(filepath + \"/nam_218_\" + str(year) + \"0\" + str(month) + str(day) +\"_1800_00\" + str(band) + \".grb2\")\n",
    "            elif (month >= 10 and day < 10):\n",
    "                lst.append(filepath + \"/nam_218_\" + str(year) + str(month) + \"0\" + str(day) +\"_1800_00\" + str(band) + \".grb2\")\n",
    "            else:\n",
    "                lst.append(filepath + \"/nam_218_\" + str(year) + str(month) + str(day) +\"_1800_00\" + str(band) + \".grb2\")\n",
    "        return lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Useful Indexes\n",
    "339: temperature at the surface (K)  \n",
    "340: soil temperature between 0.0-0.1m (K)  \n",
    "341: soil moisture content between 0.0-0.1m (proportion)  \n",
    "342: soil liquid content between 0.0-0.1m (porportion)\n",
    "343: soil temperature between 0.1-0.4m (K)  \n",
    "344: soil moisture content between 0.1-0.4m (proportion)  \n",
    "345: soil liquid content between 0.1-0.4m (porportion)  \n",
    "346: soil temperature between 0.4-1m (K)  \n",
    "347: soil moisture content between 0.4-1m (proportion)  \n",
    "348: soil liquid content between 0.4-1m (porportion)  \n",
    "349: soil temperature between 1-2m (K)  \n",
    "350: soil moisture content between 1-2m (proportion)  \n",
    "351: soil liquid content between 1-2m (porportion)  \n",
    "352: soil temperature at 3m (K)  \n",
    "355: plant surface water (kg^m-2)  \n",
    "356: water equivilant of accumulated snow depth (kg^m-2)  \n",
    "357: snow cover (%)  \n",
    "358: snow depth (m)  \n",
    "360: soil porosity (proportion)\n",
    "361: temperature at 2m above ground (K)  \n",
    "362: specific humidity at 2m above ground (kg kg^-1)  \n",
    "363: dew point temperature at 2m above ground (K)  \n",
    "364: relative humidity at 2m above ground (%)  \n",
    "367: total precipitation (kg m^-2)\n",
    "368: convective precipitation (kg m^-2)  \n",
    "371: Categorical snow  \n",
    "372: Categorical ice pellets  \n",
    "373: Categorical freezing rain  \n",
    "374: Categorical rain  \n",
    "375: Surface roughness (m)  \n",
    "378: Vegetation (%)  \n",
    "379: Vegetation Type (Integer(0-13))  \n",
    "380: Soil type  \n",
    "388: Geopotential Height (gpm)  \n",
    "436: Lightning  \n",
    "437: Land-sea mask:(0 - 1)  \n",
    "438: Sea-ice cover:(0 - 1)  \n",
    "442: Total Cloud Cover (%)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A list of all the possible filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"/media/sf_moddata/2017\"\n",
    "all_paths = get_paths(filepath, everything = 1)\n",
    "print(all_paths[0]) # 2017 january 31 18 utc band 0\n",
    "print(all_paths[-1]) # 2017 december 31 18 utc band 6\n",
    "print(len(all_paths)) # 365 days * 5 bands per day = 1825"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A list of all december file paths of band 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_paths = get_paths(filepath, 2017, 12, 0)\n",
    "print(dec_paths[0]) # december 1\n",
    "print(dec_paths[-1]) # december 31\n",
    "print(len(dec_paths)) # 31 days * 1 band per day = 31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the surface temperature of december 1st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_1_temp_surf = get_data(dec_paths[0], 339)\n",
    "print(dec_1_temp_surf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the surface temperature of the entire month of december"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_temp_surf = get_data(dec_paths, 339, everything = 1)\n",
    "print(dec_temp_surf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try printing some of this data\n",
    "rex = sns.heatmap(dec_1_temp_surf, cbar='true')\n",
    "rex.invert_yaxis() # heatmap would print it upside down if it wasn't for this\n",
    "print(np.max(dec_1_temp_surf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Scaling for NAM\n",
    "http://www.nco.ncep.noaa.gov/pmb/docs/on388/tableb.html#GRID218  \n",
    "https://jswhit.github.io/pygrib/docs/\n",
    "\n",
    "# NAIVE BAYES CLASSIFIER\n",
    "\n",
    "The code below tries to classify the surface temperature from 31N-41N, 82W-102W  \n",
    "of june 1st band 0 and dec 1st band 0  \n",
    "\n",
    "since the amount of data is just 2 days, it's not that hard to classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path, select, year, month, band, index=0):\n",
    "    \"\"\"\n",
    "    path: a string containing the path to the file where all the \".grb2\" data is stores\n",
    "    index: an integer, the type of data to be extracted (see list)\n",
    "    year, month, band: an integer\n",
    "    this function opens every file for the specified month\n",
    "    it extracts, and crops the data to 31N-41N, 82W-102W\n",
    "    returns a 2D numpy array, the rows = days of the month, the cols = the data for that specific day\n",
    "    \"\"\"\n",
    "    if (month == 1 or month == 3 or month == 5 or month == 7 or month == 8 or month == 10 or month == 12):\n",
    "        day = 31\n",
    "    elif (month == 4 or month == 6 or month == 9 or month == 11):\n",
    "        day = 30\n",
    "    else:\n",
    "        day = 28\n",
    "    paths = get_paths(path, year, month, band)\n",
    "    data = np.empty([day,13999]) # 13999, magic number from .data() function\n",
    "    for i, path in enumerate(paths):\n",
    "        grbs = pygrib.open(path) # opening file\n",
    "        grb = grbs.select(name=select)[index] # getting specific data\n",
    "        data_temp, lats, lons = grb.data(lat1=31,lat2=41,lon1=-102,lon2=-82) # 31N-41N, 82W-102W extracting\n",
    "        data[i] = data_temp\n",
    "        grbs.close() # closing file\n",
    "        print(month, i+1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JUNE 1st vs DECEMBER 1st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygrib\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# JUNE\n",
    "jun_1_path = \"/media/sf_moddata/2017/nam_218_20170601_1800_000.grb2\" # june 1st 2017\n",
    "grbs_jun_1 = pygrib.open(jun_1_path)\n",
    "grb_jun_1 = grbs_jun_1.select(name='Temperature')[39] # surface temperature\n",
    "data_jun_1, lats_jun_1, lons_jun_1 = grb_jun_1.data(lat1=31,lat2=41,lon1=-102,lon2=-82) # 31N-41N, 82W-102W\n",
    "print(\"June: \", data_jun_1.shape, lats_jun_1.shape, lons_jun_1.shape)\n",
    "grbs_jun_1.close()\n",
    "\n",
    "# DECEMBER\n",
    "dec_1_path = \"/media/sf_moddata/2017/nam_218_20171201_1800_000.grb2\" # december 1st 2017\n",
    "grbs_dec_1 = pygrib.open(dec_1_path)\n",
    "grb_dec_1 = grbs_dec_1.select(name='Temperature')[39] # surface temperature\n",
    "data_dec_1, lats_dec_1, lons_dec_1 = grb_dec_1.data(lat1=31,lat2=41,lon1=-102,lon2=-82) # 31N-41N, 82W-102W\n",
    "print(\"December: \", data_dec_1.shape, lats_dec_1.shape, lons_dec_1.shape)\n",
    "grbs_dec_1.close()\n",
    "\n",
    "# STACKING DATA\n",
    "data = np.stack((data_jun_1, data_dec_1))\n",
    "print(\"Stacked June and December: \", data.shape)\n",
    "\n",
    "# TARGET ARRAY\n",
    "target = np.array([0,1])\n",
    "print(\"Target: \", target.shape)\n",
    "# NAIVE BAYES\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(data, target).predict(data)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (data.shape[0],(target != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JUNE VS DECEMBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygrib\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "path = \"/media/sf_moddata/2017\"\n",
    "\n",
    "data_jun = get_data(path, \"Temperature\", 2017, 6, 0, 39) # \"Temperature\" and index 39 is soil temperature\n",
    "print(\"June: \", data_jun.shape)\n",
    "data_dec = get_data(path, \"Temperature\", 2017, 12, 0, 39) # \"Temperature\" and index 39 is soil temperature\n",
    "print(\"December: \", data_dec.shape)\n",
    "\n",
    "# STACKING DATA\n",
    "data = np.vstack((data_jun, data_dec))\n",
    "print(data.shape)\n",
    "\n",
    "# TARGET ARRAY\n",
    "target = np.empty(len(data))\n",
    "for i in range(len(target)):\n",
    "    if (i < 30):\n",
    "        target[i] = 0 # june\n",
    "    else:\n",
    "        target[i] = 1 # december\n",
    "print(target)\n",
    "\n",
    "# NAIVE BAYES\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(data, target).predict(data)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (data.shape[0],(target != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rex = sns.heatmap(data, cbar = 'true')\n",
    "rex.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygrib\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "path = \"/media/sf_moddata/2017\"\n",
    "\n",
    "data_nov = get_data(path, \"Temperature\", 2017, 11, 0, 39) # \"Temperature\" and index 39 is soil temperature\n",
    "print(\"Nov: \", data_nov.shape)\n",
    "data_dec = get_data(path, \"Temperature\", 2017, 12, 0, 39) # \"Temperature\" and index 39 is soil temperature\n",
    "print(\"December: \", data_dec.shape)\n",
    "\n",
    "# STACKING DATA\n",
    "data = np.vstack((data_nov, data_dec))\n",
    "print(data.shape)\n",
    "\n",
    "# TARGET ARRAY\n",
    "target = np.empty(len(data))\n",
    "for i in range(len(target)):\n",
    "    if (i < 30):\n",
    "        target[i] = 0 # june\n",
    "    else:\n",
    "        target[i] = 1 # december\n",
    "print(target)\n",
    "\n",
    "# NAIVE BAYES\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(data, target).predict(data)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (data.shape[0],(target != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rex = sns.heatmap(data, cbar = 'true')\n",
    "rex.invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAIVE BAYES CLASSIFIER FOR ENTIRE YEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_range(path, select, year, month_start, month_end, band, index = 0):\n",
    "    \"\"\"\n",
    "    path: a string containing the path to the file where all the \".grb2\" data is stores\n",
    "    select: a string, the type of data to be extracted (see list)\n",
    "    year, month_start, month_end band: an integer\n",
    "    this function opens every file for the specified month range\n",
    "    it extracts, and crops the data to 31N-41N, 82W-102W\n",
    "    returns a 2D numpy array, the rows = days of the month, the cols = the data for that specific day\n",
    "    \"\"\"\n",
    "    lst = []\n",
    "    for i in range(month_start, month_end+1):\n",
    "        lst.append(get_data(path, select, year, i, band, index))\n",
    "    temp = np.vstack((lst[0], lst[1]))\n",
    "    temp1 = temp\n",
    "    for i in range(2, len(lst)):\n",
    "        data_blah = np.vstack((temp1, lst[i]))\n",
    "        temp1 = data\n",
    "    return temp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_year():\n",
    "    \"\"\"\n",
    "    this function returns an array that labels every day in a year with the corresponding month\n",
    "    \"\"\"\n",
    "    target = np.empty(365)\n",
    "    for i in range(365):\n",
    "        if (i < 31):\n",
    "            target[i] = 1 # jan\n",
    "        elif (i < 59):\n",
    "            target[i] = 2 # feb\n",
    "        elif (i < 90):\n",
    "            target[i] = 3 # mar\n",
    "        elif (i < 120):\n",
    "            target[i] = 4 # apr\n",
    "        elif (i < 151):\n",
    "            target[i] = 5 # may\n",
    "        elif (i < 181):\n",
    "            target[i] = 6 # jun\n",
    "        elif (i < 212):\n",
    "            target[i] = 7 # jul\n",
    "        elif (i < 243):\n",
    "            target[i] = 8 # aug\n",
    "        elif (i < 273):\n",
    "            target[i] = 9 # sep\n",
    "        elif (i < 304):\n",
    "            target[i] = 10 # oct\n",
    "        elif (i < 334):\n",
    "            target[i] = 11 # nov\n",
    "        else:\n",
    "            target[i] = 12 # dec\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/media/sf_moddata/2017\"\n",
    "data = get_data(path, \"Temperature\", 2017, 1, 0, 39)\n",
    "rex = sns.heatmap(data, cbar='true')\n",
    "rex.invert_yaxis()\n",
    "#target = get_target_year()\n",
    "# NAIVE BAYES\n",
    "#gnb = GaussianNB()\n",
    "#y_pred = gnb.fit(data, target).predict(data)\n",
    "#print(\"Number of mislabeled points out of a total %d points : %d\" % (data.shape[0],(target != y_pred).sum()))\n",
    "#rex = sns.heatmap(data, cbar='true')\n",
    "#rex.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(188/365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rex = sns.heatmap(data, cbar='true')\n",
    "rex.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data, origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_data = np.empty(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in data:\n",
    "    max_data[count] = np.max(i)\n",
    "    count = count + 1\n",
    "print(max_data.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAIVE BAYES\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(max_data.reshape(-1,1), target).predict(max_data.reshape(-1,1))\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (max_data.shape[0],(target != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "k_means = KMeans(init='k-means++', n_clusters=3, n_init=10)\n",
    "k_means.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/media/sf_moddata/2017/nam_218_20170101_1800_000.grb2\"\n",
    "print_grbs(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
