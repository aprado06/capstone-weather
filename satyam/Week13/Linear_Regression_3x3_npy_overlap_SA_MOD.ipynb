{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import matplotlib.pyplot as plt; \n",
    "import pandas as pd\n",
    "plt.rcdefaults()\n",
    "%matplotlib inline\n",
    "\n",
    "import PIL\n",
    "import glob\n",
    "import scikitplot as skplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_names = [\"Band 1_11\", \"Band 1_12\", \"Band 1_13\", \n",
    "               \"Band 1_21\", \"Band 1_22\", \"Band 1_23\",\n",
    "               \"Band 1_31\", \"Band 1_32\", \"Band 1_33\",\n",
    "               \n",
    "               \n",
    "               \"Band 2_11\", \"Band 2_12\", \"Band 2_13\", \n",
    "               \"Band 2_21\", \"Band 2_22\", \"Band 2_23\",\n",
    "               \"Band 2_31\", \"Band 2_32\", \"Band 2_33\",\n",
    "               \n",
    "               \"Band 3_11\", \"Band 3_12\", \"Band 3_13\", \n",
    "               \"Band 3_21\", \"Band 3_22\", \"Band 3_23\",\n",
    "               \"Band 3_31\", \"Band 3_32\", \"Band 3_33\",\n",
    "               \n",
    "               \"Band 4_11\", \"Band 4_12\", \"Band 4_13\", \n",
    "               \"Band 4_21\", \"Band 4_22\", \"Band 4_23\",\n",
    "               \"Band 4_31\", \"Band 4_32\", \"Band 4_33\",\n",
    "               \n",
    "               \"Band 6_11\", \"Band 6_12\", \"Band 6_13\", \n",
    "               \"Band 6_21\", \"Band 6_22\", \"Band 6_23\",\n",
    "               \"Band 6_31\", \"Band 6_32\", \"Band 6_33\",\n",
    "               \n",
    "               \n",
    "               \"MRH_11\", \"MRH_12\", \"MRH_13\", \n",
    "               \"MRH_21\", \"MRH_22\", \"MRH_23\",\n",
    "               \"MRH_31\", \"MRH_32\", \"MRH_33\",\n",
    "               \n",
    "               \"MSH_11\", \"MSH_12\", \"MSH_13\", \n",
    "               \"MSH_21\", \"MSH_22\", \"MSH_23\",\n",
    "               \"MSH_31\", \"MSH_32\", \"MSH_33\",\n",
    "               \n",
    "               \"MTE_11\", \"MTE_12\", \"MTE_13\", \n",
    "               \"MTE_21\", \"MTE_22\", \"MTE_23\",\n",
    "               \"MTE_31\", \"MTE_32\", \"MTE_33\",\n",
    "               \n",
    "               \"MVI_11\", \"MVI_12\", \"MVI_13\", \n",
    "               \"MVI_21\", \"MVI_22\", \"MVI_23\",\n",
    "               \"MVI_31\", \"MVI_32\", \"MVI_33\"]\n",
    "\n",
    "X_names = np.asarray(input_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "folder = \"../satyam_rad_sat_mod_npy/\"\n",
    "Sa1_files_all = glob.glob(\"../satyam_rad_sat_mod_npy/sa1_npy/*.npy\")\n",
    "Sa1_files_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test Train Split for Files\n",
    "import random\n",
    "import math\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "random.shuffle(Sa1_files_all)\n",
    "\n",
    "Sa1_files_all.sort()\n",
    "\n",
    "size_Sa1 = len(Sa1_files_all)\n",
    "\n",
    "Sa1_files_train_size = math.ceil(size_Sa1*.75)\n",
    "Sa1_files_test_size = size_Sa1 - Sa1_files_train_size\n",
    "\n",
    "Sa1_files_train = Sa1_files_all[:Sa1_files_train_size]\n",
    "Sa1_files_test = Sa1_files_all[Sa1_files_train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.size(Sa1_files_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.size(Sa1_files_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Sa1_files_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Sa1_files_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# Extracting training images only\n",
    "for filename in Sa1_files_train:\n",
    "    filename = filename.split('/')[-1]\n",
    "    \n",
    "    # Satellite 1\n",
    "    Sa_1_File = folder + \"sa1_npy/\" + filename;\n",
    "    Sa1arr = np.load(Sa_1_File)\n",
    "    \n",
    "    \n",
    "    # Satellite 2\n",
    "    Sa_2_File = folder + \"sa2_npy/\" + filename;\n",
    "    Sa2arr = np.load(Sa_2_File)\n",
    "    \n",
    "    \n",
    "    # Satellite 3\n",
    "    Sa_3_File = folder + \"sa3_npy/\" + filename;\n",
    "    Sa3arr = np.load(Sa_3_File)\n",
    "    \n",
    "    # Satellite 4\n",
    "    Sa_4_File = folder + \"sa4_npy/\" + filename;\n",
    "    Sa4arr = np.load(Sa_4_File)\n",
    "    \n",
    "    # Satellite 6\n",
    "    Sa_6_File = folder + \"sa6_npy/\" + filename;\n",
    "    Sa6arr = np.load(Sa_6_File)\n",
    "    \n",
    "    \n",
    "    # Model Data has wrong orientation relative to the satellite\n",
    "    # Thus using flipud\n",
    "    \n",
    "    # MRH\n",
    "    MRH_File = folder + \"mrh_npy/\" + filename.replace('sat', \"mod\", 1)\n",
    "    MRHarr = np.flipud(np.load(MRH_File))\n",
    "    \n",
    "    # MSH\n",
    "    MSH_File = folder + \"msh_npy/\" + filename.replace('sat', \"mod\", 1)\n",
    "    MSHarr = np.flipud(np.load(MSH_File))\n",
    "    \n",
    "    # MTE\n",
    "    MTE_File = folder + \"tem_npy/\" + filename.replace('sat', \"mod\", 1)\n",
    "    MTEarr = np.flipud(np.load(MTE_File))\n",
    "    \n",
    "    # MVI\n",
    "    MVI_File = folder + \"vis_npy/\" + filename.replace('sat', \"mod\", 1)\n",
    "    MVIarr = np.flipud(np.load(MVI_File))\n",
    "    \n",
    "    # Radar Data has wrong orientation relative to the satellite\n",
    "    # Thus using flipud\n",
    "    \n",
    "    # Radar\n",
    "    Radar_File = folder + \"rad_npy/\" + filename.replace('sat', \"rad\", 1)\n",
    "    Radararr = np.flipud(np.load(Radar_File))\n",
    "    \n",
    "    rows = len(Sa1arr);\n",
    "    cols = len(Sa1arr[0]);\n",
    "    \n",
    "    for row in range(1, rows-1):\n",
    "        for col in range(1, cols-1):\n",
    "            x = [];\n",
    "            \n",
    "            # Sa1\n",
    "            for row_ in range(row-1, row+2):\n",
    "                for col_ in range(col-1, col+2):\n",
    "                    x.append(Sa1arr[row_][col_])\n",
    "                    \n",
    "            # Sa2\n",
    "            for row_ in range(row-1, row+2):\n",
    "                for col_ in range(col-1, col+2):\n",
    "                    x.append(Sa2arr[row_][col_])\n",
    "                    \n",
    "                    \n",
    "            # Sa3\n",
    "            for row_ in range(row-1, row+2):\n",
    "                for col_ in range(col-1, col+2):\n",
    "                    x.append(Sa3arr[row_][col_])\n",
    "                    \n",
    "            # Sa4\n",
    "            for row_ in range(row-1, row+2):\n",
    "                for col_ in range(col-1, col+2):\n",
    "                    x.append(Sa4arr[row_][col_])\n",
    "                    \n",
    "            # Sa6\n",
    "            for row_ in range(row-1, row+2):\n",
    "                for col_ in range(col-1, col+2):\n",
    "                    x.append(Sa6arr[row_][col_])\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "            # MRH\n",
    "            for row_ in range(row-1, row+2):\n",
    "                for col_ in range(col-1, col+2):\n",
    "                    x.append(MRHarr[row_][col_])    \n",
    "                    \n",
    "            # MSH\n",
    "            for row_ in range(row-1, row+2):\n",
    "                for col_ in range(col-1, col+2):\n",
    "                    x.append(MSHarr[row_][col_])\n",
    "                    \n",
    "                    \n",
    "            # MTE\n",
    "            for row_ in range(row-1, row+2):\n",
    "                for col_ in range(col-1, col+2):\n",
    "                    x.append(MTEarr[row_][col_])\n",
    "                    \n",
    "                    \n",
    "            # MVI\n",
    "            for row_ in range(row-1, row+2):\n",
    "                for col_ in range(col-1, col+2):\n",
    "                    x.append(MVIarr[row_][col_])\n",
    "                    \n",
    "            # clip 0\n",
    "            x = np.array(x)\n",
    "            x[x < 0] = 0\n",
    "            x = x.tolist()\n",
    "                    \n",
    "                    \n",
    "            y_train.append(Radararr[row][col])        \n",
    "            X_train.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(np.std(X_train))\n",
    "print(np.min(X_train))\n",
    "print(np.mean(X_train))\n",
    "print(np.max(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(y_train.shape)\n",
    "print(np.std(y_train))\n",
    "print(np.min(y_train))\n",
    "print(np.mean(y_train))\n",
    "print(np.max(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reg_train = linear_model.LinearRegression()\n",
    "reg_train.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for feat, coef in zip(X_names, reg_train.coef_):\n",
    "    print('{}       {}'.format(feat, coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_heat = np.max(reg_train.coef_)\n",
    "max_heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "feature_heatmap = np.abs(reg_train.coef_).reshape((27,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(feature_heatmap[0:3], linewidths=.01, annot=True,square=\"true\", vmin=0, vmax=max_heat ).set_title('Band 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g2 = sns.heatmap(feature_heatmap[3:6], linewidths=.01, annot=True,square=\"true\", vmin=0, vmax=max_heat).set_title('Band 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(feature_heatmap[6:9], linewidths=.01, annot=True,square=\"true\", vmin=0, vmax=max_heat).set_title('Band 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(feature_heatmap[9:12], linewidths=.01, annot=True,square=\"true\", vmin=0, vmax=max_heat).set_title('Band 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(feature_heatmap[12:15], linewidths=.01, annot=True,square=\"true\", vmin=0, vmax=max_heat).set_title('Band 6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(feature_heatmap[15:18], linewidths=.01, annot=True,square=\"true\", vmin=0, vmax=max_heat).set_title('MRH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(feature_heatmap[18:21], linewidths=.01, annot=True,square=\"true\", vmin=0, vmax=max_heat).set_title('MSH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(feature_heatmap[21:24], linewidths=.01, annot=True, square=\"true\", vmin=0, vmax=max_heat/10).set_title('MTE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(feature_heatmap[24:27], linewidths=.01, annot=True, square=True, vmin=0, vmax=max_heat/10).set_title('MVI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluate the Trained output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_train = reg_train.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "errors_train = abs(predictions_train - y_train)\n",
    "np.max(errors_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(y_train, density=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(errors_train, density=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_no_zero = list(filter(lambda a: a != 0, y_train))\n",
    "print(np.shape(y_train_no_zero))\n",
    "print(np.std(y_train_no_zero))\n",
    "print(np.min(y_train_no_zero))\n",
    "print(np.mean(y_train_no_zero))\n",
    "print(np.max(y_train_no_zero))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thershold = np.mean(y_train_no_zero) + 1 * np.std(y_train_no_zero)\n",
    "thershold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_copy = np.copy(y_train)\n",
    "y_train_copy[y_train_copy < thershold] = 0\n",
    "y_train_copy[y_train_copy >= thershold] = 1\n",
    "\n",
    "predictions_train_copy = np.copy(predictions_train)\n",
    "predictions_train_copy[predictions_train_copy < thershold] = 0\n",
    "predictions_train_copy[predictions_train_copy >= thershold] = 1\n",
    "\n",
    "skplt.metrics.plot_confusion_matrix(y_train_copy, predictions_train_copy, normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "FPR = []\n",
    "TPR = []\n",
    "\n",
    "for i in range(1, 531, 10):\n",
    "    y_train_copy = np.copy(y_train)\n",
    "    y_train_copy[y_train_copy < i] = 0\n",
    "    y_train_copy[y_train_copy >= i] = 1\n",
    "\n",
    "    predictions_train_copy = np.copy(predictions_train)\n",
    "    predictions_train_copy[predictions_train_copy < i] = 0\n",
    "    predictions_train_copy[predictions_train_copy >= i] = 1\n",
    "    \n",
    "    temp = confusion_matrix(y_train_copy, predictions_train_copy)\n",
    "    \n",
    "    TN = temp[0][0]\n",
    "    FP = temp[0][1]\n",
    "    FN = temp[1][0]\n",
    "    TP = temp[1][1]\n",
    "    \n",
    "    TPR_ = TP/(TP+FN)\n",
    "    FPR_ = FP/(TN+FP)\n",
    "    \n",
    "    FPR.append(FPR_)\n",
    "    TPR.append(TPR_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(FPR, TPR, label='ROC')\n",
    "plt.plot([0,1], [0,1], linestyle='dashed')\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\");\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the Model\n",
    "import pickle\n",
    "filename = 'MODEL_OUT_Final_Linear_Regression_3x3_npy_SA_MOD.sav'\n",
    "pickle.dump(reg_train, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
