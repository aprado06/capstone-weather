{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import matplotlib.pyplot as plt; \n",
    "import pandas as pd\n",
    "plt.rcdefaults()\n",
    "%matplotlib inline\n",
    "\n",
    "import PIL\n",
    "import glob\n",
    "import scikitplot as skplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_names = [\"Band 1_11\", \"Band 1_12\", \"Band 1_13\", \"Band 1_14\", \"Band 1_15\", \n",
    "               \"Band 1_21\", \"Band 1_22\", \"Band 1_23\", \"Band 1_24\", \"Band 1_25\", \n",
    "               \"Band 1_31\", \"Band 1_32\", \"Band 1_33\", \"Band 1_34\", \"Band 1_35\",\n",
    "               \"Band 1_41\", \"Band 1_42\", \"Band 1_43\", \"Band 1_44\", \"Band 1_45\",\n",
    "               \"Band 1_51\", \"Band 1_52\", \"Band 1_53\", \"Band 1_54\", \"Band 1_55\",\n",
    "               \n",
    "               \n",
    "               \"Band 2_11\", \"Band 2_12\", \"Band 2_13\", \"Band 2_14\", \"Band 2_15\", \n",
    "               \"Band 2_21\", \"Band 2_22\", \"Band 2_23\", \"Band 2_24\", \"Band 2_25\", \n",
    "               \"Band 2_31\", \"Band 2_32\", \"Band 2_33\", \"Band 2_34\", \"Band 2_35\",\n",
    "               \"Band 2_41\", \"Band 2_42\", \"Band 2_43\", \"Band 2_44\", \"Band 2_45\",\n",
    "               \"Band 2_51\", \"Band 2_52\", \"Band 2_53\", \"Band 2_54\", \"Band 2_55\",\n",
    "               \n",
    "               \n",
    "               \"Band 3_11\", \"Band 3_12\", \"Band 3_13\", \"Band 3_14\", \"Band 3_15\", \n",
    "               \"Band 3_21\", \"Band 3_22\", \"Band 3_23\", \"Band 3_24\", \"Band 3_25\", \n",
    "               \"Band 3_31\", \"Band 3_32\", \"Band 3_33\", \"Band 3_34\", \"Band 3_35\",\n",
    "               \"Band 3_41\", \"Band 3_42\", \"Band 3_43\", \"Band 3_44\", \"Band 3_45\",\n",
    "               \"Band 3_51\", \"Band 3_52\", \"Band 3_53\", \"Band 3_54\", \"Band 3_55\",\n",
    "               \n",
    "               \n",
    "               \"Band 4_11\", \"Band 4_12\", \"Band 4_13\", \"Band 4_14\", \"Band 4_15\", \n",
    "               \"Band 4_21\", \"Band 4_22\", \"Band 4_23\", \"Band 4_24\", \"Band 4_25\", \n",
    "               \"Band 4_31\", \"Band 4_32\", \"Band 4_33\", \"Band 4_34\", \"Band 4_35\",\n",
    "               \"Band 4_41\", \"Band 4_42\", \"Band 4_43\", \"Band 4_44\", \"Band 4_45\",\n",
    "               \"Band 4_51\", \"Band 4_52\", \"Band 4_53\", \"Band 4_54\", \"Band 4_55\",\n",
    "               \n",
    "               \"Band 5_11\", \"Band 5_12\", \"Band 5_13\", \"Band 5_14\", \"Band 5_15\", \n",
    "               \"Band 5_21\", \"Band 5_22\", \"Band 5_23\", \"Band 5_24\", \"Band 5_25\", \n",
    "               \"Band 5_31\", \"Band 5_32\", \"Band 5_33\", \"Band 5_34\", \"Band 5_35\",\n",
    "               \"Band 5_41\", \"Band 5_42\", \"Band 5_43\", \"Band 5_44\", \"Band 5_45\",\n",
    "               \"Band 5_51\", \"Band 5_52\", \"Band 5_53\", \"Band 5_54\", \"Band 5_55\",\n",
    "               \n",
    "               \n",
    "               \"MRH 5_11\", \"MRH 5_12\", \"MRH 5_13\", \"MRH 5_14\", \"MRH 5_15\", \n",
    "               \"MRH 5_21\", \"MRH 5_22\", \"MRH 5_23\", \"MRH 5_24\", \"MRH 5_25\", \n",
    "               \"MRH 5_31\", \"MRH 5_32\", \"MRH 5_33\", \"MRH 5_34\", \"MRH 5_35\",\n",
    "               \"MRH 5_41\", \"MRH 5_42\", \"MRH 5_43\", \"MRH 5_44\", \"MRH 5_45\",\n",
    "               \"MRH 5_51\", \"MRH 5_52\", \"MRH 5_53\", \"MRH 5_54\", \"MRH 5_55\",\n",
    "               \n",
    "               \n",
    "               \"MSH 5_11\", \"MSH 5_12\", \"MSH 5_13\", \"MSH 5_14\", \"MSH 5_15\", \n",
    "               \"MSH 5_21\", \"MSH 5_22\", \"MSH 5_23\", \"MSH 5_24\", \"MSH 5_25\", \n",
    "               \"MSH 5_31\", \"MSH 5_32\", \"MSH 5_33\", \"MSH 5_34\", \"MSH 5_35\",\n",
    "               \"MSH 5_41\", \"MSH 5_42\", \"MSH 5_43\", \"MSH 5_44\", \"MSH 5_45\",\n",
    "               \"MSH 5_51\", \"MSH 5_52\", \"MSH 5_53\", \"MSH 5_54\", \"MSH 5_55\",\n",
    "               \n",
    "               \"MTE 5_11\", \"MTE 5_12\", \"MTE 5_13\", \"MTE 5_14\", \"MTE 5_15\", \n",
    "               \"MTE 5_21\", \"MTE 5_22\", \"MTE 5_23\", \"MTE 5_24\", \"MTE 5_25\", \n",
    "               \"MTE 5_31\", \"MTE 5_32\", \"MTE 5_33\", \"MTE 5_34\", \"MTE 5_35\",\n",
    "               \"MTE 5_41\", \"MTE 5_42\", \"MTE 5_43\", \"MTE 5_44\", \"MTE 5_45\",\n",
    "               \"MTE 5_51\", \"MTE 5_52\", \"MTE 5_53\", \"MTE 5_54\", \"MTE 5_55\",\n",
    "            \n",
    "               \n",
    "               \"MVI 5_11\", \"MVI 5_12\", \"MVI 5_13\", \"MVI 5_14\", \"MVI 5_15\", \n",
    "               \"MVI 5_21\", \"MVI 5_22\", \"MVI 5_23\", \"MVI 5_24\", \"MVI 5_25\", \n",
    "               \"MVI 5_31\", \"MVI 5_32\", \"MVI 5_33\", \"MVI 5_34\", \"MVI 5_35\",\n",
    "               \"MVI 5_41\", \"MVI 5_42\", \"MVI 5_43\", \"MVI 5_44\", \"MVI 5_45\",\n",
    "               \"MVI 5_51\", \"MVI 5_52\", \"MVI 5_53\", \"MVI 5_54\", \"MVI 5_55\"]\n",
    "\n",
    "X_names = np.asarray(input_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "folder = \"../satyam_rad_sat_mod_npy/\"\n",
    "Sa1_files_all = glob.glob(\"../satyam_rad_sat_mod_npy/sa1_npy/*.npy\")\n",
    "Sa1_files_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test Train Split for Files\n",
    "import random\n",
    "import math\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "random.shuffle(Sa1_files_all)\n",
    "\n",
    "Sa1_files_all.sort()\n",
    "\n",
    "size_Sa1 = len(Sa1_files_all)\n",
    "\n",
    "Sa1_files_train_size = math.ceil(size_Sa1*.75)\n",
    "Sa1_files_test_size = size_Sa1 - Sa1_files_train_size\n",
    "\n",
    "Sa1_files_train = Sa1_files_all[:Sa1_files_train_size]\n",
    "Sa1_files_test = Sa1_files_all[Sa1_files_train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.size(Sa1_files_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.size(Sa1_files_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Sa1_files_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Sa1_files_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# Extracting training images only\n",
    "for filename in Sa1_files_train:\n",
    "    filename = filename.split('/')[-1]\n",
    "    \n",
    "    # Satellite 1\n",
    "    Sa_1_File = folder + \"sa1_npy/\" + filename;\n",
    "    Sa1arr = np.load(Sa_1_File)\n",
    "    \n",
    "    \n",
    "    # Satellite 2\n",
    "    Sa_2_File = folder + \"sa2_npy/\" + filename;\n",
    "    Sa2arr = np.load(Sa_2_File)\n",
    "    \n",
    "    \n",
    "    # Satellite 3\n",
    "    Sa_3_File = folder + \"sa3_npy/\" + filename;\n",
    "    Sa3arr = np.load(Sa_3_File)\n",
    "    \n",
    "    # Satellite 4\n",
    "    Sa_4_File = folder + \"sa4_npy/\" + filename;\n",
    "    Sa4arr = np.load(Sa_4_File)\n",
    "    \n",
    "    # Satellite 6\n",
    "    Sa_6_File = folder + \"sa6_npy/\" + filename;\n",
    "    Sa6arr = np.load(Sa_6_File)\n",
    "    \n",
    "    \n",
    "    # Model Data has wrong orientation relative to the satellite\n",
    "    # Thus using flipud\n",
    "    \n",
    "    # MRH\n",
    "    MRH_File = folder + \"mrh_npy/\" + filename.replace('sat', \"mod\", 1)\n",
    "    MRHarr = np.flipud(np.load(MRH_File))\n",
    "    \n",
    "    # MSH\n",
    "    MSH_File = folder + \"msh_npy/\" + filename.replace('sat', \"mod\", 1)\n",
    "    MSHarr = np.flipud(np.load(MSH_File))\n",
    "    \n",
    "    # MTE\n",
    "    MTE_File = folder + \"tem_npy/\" + filename.replace('sat', \"mod\", 1)\n",
    "    MTEarr = np.flipud(np.load(MTE_File))\n",
    "    \n",
    "    # MVI\n",
    "    MVI_File = folder + \"vis_npy/\" + filename.replace('sat', \"mod\", 1)\n",
    "    MVIarr = np.flipud(np.load(MVI_File))\n",
    "    \n",
    "    # Radar Data has wrong orientation relative to the satellite\n",
    "    # Thus using flipud\n",
    "    \n",
    "    # Radar\n",
    "    Radar_File = folder + \"rad_npy/\" + filename.replace('sat', \"rad\", 1)\n",
    "    Radararr = np.flipud(np.load(Radar_File))\n",
    "    \n",
    "    rows = len(Sa1arr);\n",
    "    cols = len(Sa1arr[0]);\n",
    "    \n",
    "    \n",
    "    for row in range(2, rows-2):\n",
    "        for col in range(2, cols-2):\n",
    "            x = [];\n",
    "            \n",
    "            # Sa1\n",
    "            for row_ in range(row-2, row+3):\n",
    "                for col_ in range(row-2, row+3):\n",
    "                    x.append(Sa1arr[row_][col_])\n",
    "                    \n",
    "            # Sa2\n",
    "            for row_ in range(row-2, row+3):\n",
    "                for col_ in range(row-2, row+3):\n",
    "                    x.append(Sa2arr[row_][col_])\n",
    "                    \n",
    "                    \n",
    "            # Sa3\n",
    "            for row_ in range(row-2, row+3):\n",
    "                for col_ in range(row-2, row+3):\n",
    "                    x.append(Sa3arr[row_][col_])\n",
    "                    \n",
    "            # Sa4\n",
    "            for row_ in range(row-2, row+3):\n",
    "                for col_ in range(row-2, row+3):\n",
    "                    x.append(Sa4arr[row_][col_])\n",
    "                    \n",
    "            # Sa6\n",
    "            for row_ in range(row-2, row+3):\n",
    "                for col_ in range(row-2, row+3):\n",
    "                    x.append(Sa6arr[row_][col_])\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "            # MRH\n",
    "            for row_ in range(row-2, row+3):\n",
    "                for col_ in range(row-2, row+3):\n",
    "                    x.append(MRHarr[row_][col_])    \n",
    "                    \n",
    "            # MSH\n",
    "            for row_ in range(row-2, row+3):\n",
    "                for col_ in range(row-2, row+3):\n",
    "                    x.append(MSHarr[row_][col_])\n",
    "                    \n",
    "                    \n",
    "            # MTE\n",
    "            for row_ in range(row-2, row+3):\n",
    "                for col_ in range(row-2, row+3):\n",
    "                    x.append(MTEarr[row_][col_])\n",
    "                    \n",
    "                    \n",
    "            # MVI\n",
    "            for row_ in range(row-2, row+3):\n",
    "                for col_ in range(row-2, row+3):\n",
    "                    x.append(MVIarr[row_][col_])\n",
    "                    \n",
    "            # clip 0\n",
    "            x = np.array(x)\n",
    "            x[x < 0] = 0\n",
    "            x = x.tolist()\n",
    "                    \n",
    "                    \n",
    "            y_train.append(Radararr[row][col])        \n",
    "            X_train.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(np.std(X_train))\n",
    "print(np.min(X_train))\n",
    "print(np.mean(X_train))\n",
    "print(np.max(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(y_train.shape)\n",
    "print(np.std(y_train))\n",
    "print(np.min(y_train))\n",
    "print(np.mean(y_train))\n",
    "print(np.max(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reg_train = linear_model.LinearRegression()\n",
    "reg_train.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for feat, coef in zip(X_names, reg_train.coef_):\n",
    "    print('{}       {}'.format(feat, coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_heat = np.max(reg_train.coef_)\n",
    "max_heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "feature_heatmap = np.abs(reg_train.coef_).reshape((45,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(feature_heatmap[0:5], linewidths=.01, annot=True,square=\"true\", vmin=0, vmax=max_heat/10).set_title('Band 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g2 = sns.heatmap(feature_heatmap[5:10], linewidths=.01, annot=True,square=\"true\", vmin=0, vmax=max_heat/10).set_title('Band 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(feature_heatmap[10:15], linewidths=.01, annot=True,square=\"true\", vmin=0, vmax=max_heat/10).set_title('Band 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(feature_heatmap[15:20], linewidths=.01, annot=True,square=\"true\", vmin=0, vmax=max_heat/10).set_title('Band 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(feature_heatmap[20:25], linewidths=.01, annot=True,square=\"true\", vmin=0, vmax=max_heat/10).set_title('Band 6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(feature_heatmap[25:30], linewidths=.01, annot=True,square=\"true\", vmin=0, vmax=max_heat/10).set_title('MRH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(feature_heatmap[30:35], linewidths=.01, annot=True,square=\"true\", vmin=0, vmax=max_heat).set_title('MSH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(feature_heatmap[35:40], linewidths=.01, annot=True, square=\"true\", vmin=0, vmax=max_heat).set_title('MTE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(feature_heatmap[40:45], linewidths=.01, annot=True, square=True, vmin=0, vmax=max_heat).set_title('MVI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluate the Trained output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_train = reg_train.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "errors_train = abs(predictions_train - y_train)\n",
    "np.max(errors_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(y_train, density=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(errors_train, density=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_no_zero = list(filter(lambda a: a != 0, y_train))\n",
    "print(np.shape(y_train_no_zero))\n",
    "print(np.std(y_train_no_zero))\n",
    "print(np.min(y_train_no_zero))\n",
    "print(np.mean(y_train_no_zero))\n",
    "print(np.max(y_train_no_zero))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thershold = np.mean(y_train_no_zero) + 1 * np.std(y_train_no_zero)\n",
    "thershold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_copy = np.copy(y_train)\n",
    "y_train_copy[y_train_copy < thershold] = 0\n",
    "y_train_copy[y_train_copy >= thershold] = 1\n",
    "\n",
    "predictions_train_copy = np.copy(predictions_train)\n",
    "predictions_train_copy[predictions_train_copy < thershold] = 0\n",
    "predictions_train_copy[predictions_train_copy >= thershold] = 1\n",
    "\n",
    "skplt.metrics.plot_confusion_matrix(y_train_copy, predictions_train_copy, normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "FPR = []\n",
    "TPR = []\n",
    "\n",
    "for i in range(1, 531, 10):\n",
    "    y_train_copy = np.copy(y_train)\n",
    "    y_train_copy[y_train_copy < i] = 0\n",
    "    y_train_copy[y_train_copy >= i] = 1\n",
    "\n",
    "    predictions_train_copy = np.copy(predictions_train)\n",
    "    predictions_train_copy[predictions_train_copy < i] = 0\n",
    "    predictions_train_copy[predictions_train_copy >= i] = 1\n",
    "    \n",
    "    temp = confusion_matrix(y_train_copy, predictions_train_copy)\n",
    "    \n",
    "    TN = temp[0][0]\n",
    "    FP = temp[0][1]\n",
    "    FN = temp[1][0]\n",
    "    TP = temp[1][1]\n",
    "    \n",
    "    TPR_ = TP/(TP+FN)\n",
    "    FPR_ = FP/(TN+FP)\n",
    "    \n",
    "    FPR.append(FPR_)\n",
    "    TPR.append(TPR_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(FPR, TPR, label='ROC')\n",
    "plt.plot([0,1], [0,1], linestyle='dashed')\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\");\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the Model\n",
    "import pickle\n",
    "filename = 'MODEL_OUT_Final_Linear_Reg_5x5_npy_SA_MOD.sav'\n",
    "pickle.dump(reg_train, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
